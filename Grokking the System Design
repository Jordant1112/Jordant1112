Step by Step guide
#1. Requirements clarifications
#2 Back-of-the-envelope estimation
#3 System Interface definition
#4 Defining data model
#5 High-level design
#6 Detailed design
#7 Identifying and resolving bottlenecks


Reasons for SQL:
  1. Structured Data, 2. Strict Schema, 3. Relational data, 4. Need for complex joins, 
  5. Transactions 6. Clear patterns for scaling, 7. More established: developers, community, code, tools, etc
  8. Lookups by index are very fast

Reasons for NoSQL:
  1. Semi-structured data 2. Dynamic or flexible schema, 3. Non-relational data 4. No need for complex joins. 5. Store many TB or PB of data
  6. Very data intensive workload 7. Very high throughput for IOPS
  Sample data well-suited for NoSQL:
    Rapid ingest of clickstream and log data
    Leaderboard or scroing data
    Temporary data, such as a shopping cart
    Frequently accessed ('hot') tables
    Metadat/ lookup tables

High level differences between SQL and NoSQL

Storage: SQL stores data in tables, where each row represents an entity, and each column represents a data point about that entity. For example,
if we are stroing a car entity in a table, different columns could be 'color', 'make'. 'model', and so on.

NoSQL data bases have different data storage models. The main ones are key-value, document, graph, and columnar.

Schema: In SQL, each record conforms to a fixed schema, meaning the columns must be decided and chosen before data entry and each row must have data for each column.
The schema can be altered later, but it involves modifying the whole database and going offline

Whereas in NoSQl, schemas are dynamic. Columns can be added on the fly, and each 'row' (or equivalent) doesn't have to contain data for each column

Querying: SQL databases uses SQL (structured query language) for defining and manipulating the data, which is very powerful. In NoSQL database, queries are focused on a collection 
of documents. Sometimes it is also called UNQL (Unstructured Query Language) Different databases have different syntax for using UnQL

Scalability： In most common situations, SQL DB are vertically scalable, by increasing the hardware (expensive). It is possible to scale a relational DB across multiple servers
but it is challenging and time-consuming process.

NoSQL DB is horizontally scalable, meaning we can add more servers easily in our NoSQL DB infrastructure to handle large traffic. 

Reliability or ACID (Automicity, Consistency, Isolation, Durability): When it comes to data reliability and safe guarantee of performing transactions, SQL is the better bet.


Polling VS. Push
Problem with Pooling is that the client has to keep asking the server for any new data. As a result, a lot of responses are empty creating HTTP overhead 

Websockets: full duplex. allows communication between both direction simultaneously over a single TCP connection. 



### TinyURL example

# Goals and Requirements of the System

Functional Requirements:
Given a URL, our service should generate a shorter and unique alias of it. This is called a short link. This link should be short enough to be easily copied and pasted into applications.
When users access a short link, our service should redirect them to the original link.
Users should optionally be able to pick a custom short link for their URL.
Links will expire after a standard default timespan. Users should be able to specify the expiration time.

Non-Functional Requirements:
The system should be highly available. This is required because, if our service is down, all the URL redirections will start failing.
URL redirection should happen in real-time with minimal latency.
Shortened links should not be guessable (not predictable).


Extended Requirements:
Analytics; e.g., how many times a redirection happened?
Our service should also be accessible through REST APIs by other services.


#Capacity Estimation and Constraints

Assuming 100:1 read and write ratio
Traffic Estimation: 
say 500 M new URL shrotenings permonth, 100:1 read/write ration:  100*500 M == 50 B
QPS (queries Per Second) 500 M / (30 days * 24 hours * 3600 seconds) = ~200 URLs/s   for write
100 * 200 URLs/s = 20k URLs/s for read

Storage Estimation:
Let’s assume we store every URL shortening request (and associated shortened link) for 5 years. 
Since we expect to have 500M new URLs every month, the total number of objects we expect to store will be 30 billion:

500 M * 5 Years * 12 Months = 30 B  if each is 500 bytes then the total storage --> 15 TB

Bandwidth estimates:

For write requests, since we expect 200 new URLs every second, total incoming data for our service will be 100KB per second:
200 URLs/s * 500 bytes = 100 KB/s

For read requests, since every second we expect ~20K URLs redirections, total outgoing data for our service would be 10MB per second
20K * 500 bytes = 10 MB/s

Memory estimates:

If we want to cache some of the hot URLs, following 80-20 rule with 20% of URLS generate 80% of traffic, we need to cache these 20% hot URLS

with 20K requests per second, 20K * 3600 seconds * 24 hours = ~ 1.7 Billion requests per day, then cache 20% of it would be 

0.2 * 1.7 N * 500 bytes = ~ 170 GB
NOTE: since there will be many duplicate requests (pof the same URL), the memory will be less than 170GB

HIGH LEVEL ESTIMATES: ASSUMING 500 Million new URLs permonth and 100:1 read:write ratio.
New URLS : 200/s
URL redirections 20 K/s
Incoming data: 100 KB/s
Outgoing data: 10 MB/s
Storage for 5 years: 15 TB
Memory for cache: 170 GB

####System APIs

createURL(api_dev_key, original_url, custom_alias=None, user_name=None, expire_date = None)

Parameters:
api_dev_key (string): The API developer key of a registered account. This will be used to, among other things, throttle users based on their allocated quota.
original_url (string): Original URL to be shortened.
custom_alias (string): Optional custom key for the URL.
user_name (string): Optional user name to be used in the encoding.
expire_date (string): Optional expiration date for the shortened URL.

deleteURL(api_dev_key, url_key) 

Where “url_key” is a string representing the shortened URL to be retrieved; a successful deletion returns ‘URL Removed’.

#### Databased Design
We need to store billions of records.
Each object we store is small (less than 1K).
There are no relationships between records—other than storing which user created a URL.
Our service is read-heavy.

#### Basic System Design and Algorithm
a. Encoding actual URL
compute hash by MD5 or SHA 256 of the given URL. 
Using base64 encoding, a 6 letters long key would result in 64^6 = ~68.7 billion possible strings.
Using base64 encoding, an 8 letters long key would result in 64^8 = ~281 trillion possible strings.


What are the different issues with our solution? We have the following couple of problems with our encoding scheme:

If multiple users enter the same URL, they can get the same shortened URL, which is not acceptable.
What if parts of the URL are URL-encoded? e.g., http://www.educative.io/distributed.php?id=design, 
and http://www.educative.io/distributed.php%3Fid%3Ddesign are identical except for the URL encoding.

b.generating keys offline
Key Generation Service (KGS) and stroe it in key-DB

KEy Db Size: 6 (characters per key) * 68.7B (unique keys) = 412 GB.

#### Data Partitioning and Replication
To scale out our DB, we need to partition it so that it can store information about billions of URLs. 
Therefore, we need to develop a partitioning scheme that would divide and store our data into different DB servers.

a. Range Based Partitioning which stores URL based on certain patterns i.e., starting with 'A', 'B'.
The issue for this approach is that it can lead to unbalanced DB servers. 

b. Hash-Based Partitioning: 
In this scheme, we take a hash of the object we are storing. We then calculate which partition to use based upon the hash. 
In our case, we can take the hash of the ‘key’ or the short link to determine the partition in which we store the data object.

Our hashing function will randomly distribute URLs into different partitions (e.g., our hashing function can always map any ‘key’ to a number between [1…256]). 
This number would represent the partition in which we store our object.

This approach can still lead to overloaded partitions, which can be solved using Consistent Hashing.























